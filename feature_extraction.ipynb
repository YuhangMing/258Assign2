{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n",
      "\n",
      "Sample data:\n",
      "{u'province': u'Sicily & Sardinia', u'region_2': None, u'description': u\"Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\", u'designation': u'Vulk\\xe0 Bianco', u'title': u'Nicosia 2013 Vulk\\xe0 Bianco  (Etna)', u'region_1': u'Etna', u'country': u'Italy', u'taster_name': u'Kerin O\\u2019Keefe', u'variety': u'White Blend', u'points': u'87', u'winery': u'Nicosia', u'price': None, u'taster_twitter_handle': u'@kerinokeefe'}\n",
      "Sicily & Sardinia\n",
      "Length of the dataset is 129971\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print 'Reading data...'\n",
    "data = json.load(open('winemag-data-130k-v2.json'))\n",
    "print 'done\\n'\n",
    "print 'Sample data:'\n",
    "print(data[0])\n",
    "print data[0]['province']\n",
    "print('Length of the dataset is ' + str(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000 samples for taining and 9971 samples for testing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# shuffle and split dataset\n",
    "random.shuffle(data)\n",
    "# print(data[0])\n",
    "train = data[:120000]\n",
    "test = data[120000:]\n",
    "print( str(len(train)) + ' samples for taining and ' + str(len(test)) + ' samples for testing\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating features...\n"
     ]
    }
   ],
   "source": [
    "print 'Creating features...'\n",
    "# extract feature for training set and testing set\n",
    "punct = set(string.punctuation)\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "# sw = nltk.corpus.stopwords.words('english')\n",
    "# print sw\n",
    "# get necessary overall information\n",
    "# one-hot encoded info\n",
    "variety_all = []\n",
    "winery_all = []\n",
    "regions1_all = []\n",
    "word_all = []\n",
    "wordCount = defaultdict(int) # # of appearance of w in all documents\n",
    "docCount = defaultdict(int) # # of docs of all docs that contains word w\n",
    "tf = []\n",
    "\n",
    "desig_word_all = []\n",
    "desigWordCount = defaultdict(int)\n",
    "desigDocCount = defaultdict(int)\n",
    "desigTf = []\n",
    "for l in train:\n",
    "    if l['variety'] not in variety_all:\n",
    "        variety_all.append(l['variety'])\n",
    "    if l['winery'] not in winery_all:\n",
    "        winery_all.append(l['winery'])\n",
    "    if l['region_1'] not in regions1_all:\n",
    "        regions1_all.append(l['region_1'])\n",
    "\n",
    "    wordCountTmp = defaultdict(int)\n",
    "    for w in l['description'].split():\n",
    "        w = ''.join([c for c in w.lower() if not c in punct])\n",
    "        if w not in stopwords.words('english'):\n",
    "            w = stemmer.stem(w)\n",
    "            if w not in word_all:\n",
    "                word_all.append(w)\n",
    "            wordCount[w] += 1\n",
    "            wordCountTmp[w] += 1\n",
    "            if w not in docCount.keys():\n",
    "                docCount[w] += 1\n",
    "    tf.append(wordCountTmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('number of words in training' + str(len(word_all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create features\n",
    "feat_descrip = []\n",
    "feat_desig = []\n",
    "feat_points = []\n",
    "feat_price = []\n",
    "feat_variety = []\n",
    "feat_winery = []\n",
    "idx = 0\n",
    "for l in train:\n",
    "    tmpDescrip = np.zeros(shape=(len(word_all)))\n",
    "    for w in l['description'].split():\n",
    "        w = ''.join([c for c in w.lower() if not c in punct])\n",
    "        if w not in stopwords.words('english'):\n",
    "            w = stemmer.stem(w)\n",
    "            wordIdx = word_all.index(w)\n",
    "            tmpDescrip[wordIdx] = tf[idx][w] * np.log(120000/docCount[w])\n",
    "    feat_descrip.append(tmpDescrip)\n",
    "    # tmpDesig = np.zeros(shape=(len(desig_word_all)))\n",
    "    # for w in l['designation'].split():\n",
    "    #     w = ''.join([c for c in w.lower() if not c in punct])\n",
    "    #     w = stemmer.stem(w)\n",
    "    #     wordIdx = desig_word_all.index(w)\n",
    "    #     tmpDesig[wordIdx] = tf[idx][w] * np.log(120000/docCOunt[w])\n",
    "    # feat_desig.append(tmpDesig)\n",
    "    feat_points.append(l['points'])\n",
    "    feat_price.append(l['price'])\n",
    "    tmpVariety = np.zeros(shape=(len(variety_all)))\n",
    "    feat_variety.append(tmpVariety[variety_all.index(l['variety'])])\n",
    "    tmpWinery = np.zeros(shape=(len(winery_all)))\n",
    "    feat_winery.append(tmpWinery[winery_all.index(l['winery'])])\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "variety_all = []\n",
    "winery_all = []\n",
    "regions1_all = []\n",
    "word_all = []\n",
    "wordCount = defaultdict(int) # # of appearance of w in all documents\n",
    "docCount = defaultdict(int) # # of docs of all docs that contains word w\n",
    "tf = []\n",
    "\n",
    "print 'Creating features...'\n",
    "# desig_word_all = []\n",
    "# desigWordCount = defaultdict(int)\n",
    "# desigDocCount = defaultdict(int)\n",
    "# desigTf = []\n",
    "for l in test:\n",
    "    if l['variety'] not in variety_all:\n",
    "        variety_all.append(l['variety'])\n",
    "    if l['winery'] not in winery_all:\n",
    "        winery_all.append(l['winery'])\n",
    "    if l['region_1'] not in regions1_all:\n",
    "        regions1_all.append(l['region_1'])\n",
    "\n",
    "    wordCountTmp = defaultdict(int)\n",
    "    for w in l['description'].split():\n",
    "        w = ''.join([c for c in w.lower() if not c in punct])\n",
    "        if w not in stopwords.words('english'):\n",
    "            w = stemmer.stem(w)\n",
    "            if w not in word_all:\n",
    "                word_all.append(w)\n",
    "            wordCount[w] += 1\n",
    "            wordCountTmp[w] += 1\n",
    "            if w not in docCount.keys():\n",
    "                docCount[w] += 1\n",
    "    tf.append(wordCountTmp)\n",
    "\n",
    "print('number of words in training' + str(len(word_all)))\n",
    "\n",
    "# Create features\n",
    "feat_descrip_test = []\n",
    "# feat_desig = []\n",
    "feat_points_test = []\n",
    "feat_price_test = []\n",
    "feat_variety_test = []\n",
    "feat_winery_test = []\n",
    "idx = 0\n",
    "for l in test:\n",
    "    tmpDescrip = np.zeros(shape=(len(word_all)))\n",
    "    for w in l['description'].split():\n",
    "        w = ''.join([c for c in w.lower() if not c in punct])\n",
    "        if w not in stopwords.words('english'):\n",
    "            w = stemmer.stem(w)\n",
    "            wordIdx = word_all.index(w)\n",
    "            tmpDescrip[wordIdx] = tf[idx][w] * np.log(9971/docCount[w])\n",
    "    feat_descrip_test.append(tmpDescrip)\n",
    "    # tmpDesig = np.zeros(shape=(len(desig_word_all)))\n",
    "    # for w in l['designation']:\n",
    "    #     w = ''.join([c for c in w.lower() if not c in punct])\n",
    "    #     w = stemmer.stem(w)\n",
    "    #     wordIdx = desig_word_all.index(w)\n",
    "    #     tmpDesig[wordIdx] = tf[idx][w] * np.log(9971/docCOunt[w])\n",
    "    # feat_desig.append(tmpDesig)\n",
    "    feat_points_test.append(l['points'])\n",
    "    feat_price_test.append(l['price'])\n",
    "    tmpVariety = np.zeros(shape=(len(variety_all)))\n",
    "    feat_variety_test.append(tmpVariety[variety_all.index(l['variety'])])\n",
    "    tmpWinery = np.zeros(shape=(len(winery_all)))\n",
    "    feat_winery_test.append(tmpWinery[winery_all.index(l['winery'])])\n",
    "    idx += 1    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
